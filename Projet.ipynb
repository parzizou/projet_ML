{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr√©diction de l'Attrition des Employ√©s\n",
    "\n",
    "## Objectif du Notebook\n",
    "\n",
    "Ce notebook a pour but de construire un mod√®le de Machine Learning capable de **pr√©dire l'attrition des employ√©s** (d√©part de l'entreprise) et d'**analyser les facteurs** qui influencent cette d√©cision.\n",
    "\n",
    "### Plan du Notebook\n",
    "\n",
    "1. **Extraction des donn√©es** - Chargement des CSV et feature engineering\n",
    "2. **Analyse exploratoire** - Visualisations et corr√©lations\n",
    "3. **Nettoyage des donn√©es** - Suppression colonnes probl√©matiques et imputation\n",
    "4. **Pipeline ML** - Pr√©paration, entra√Ænement et tuning des mod√®les\n",
    "5. **Analyse du mod√®le** - Interpr√©tation et feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Imports et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_curve, roc_auc_score,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "\n",
    "# Model persistence\n",
    "import joblib\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1Ô∏è Extraction des Donn√©es\n",
    "\n",
    "Nous avons 5 fichiers CSV √† charger et fusionner :\n",
    "- `general_data.csv` : Informations g√©n√©rales sur les employ√©s\n",
    "- `employee_survey_data.csv` : Donn√©es de satisfaction des employ√©s\n",
    "- `manager_survey_data.csv` : √âvaluations des managers\n",
    "- `in_time.csv` : Heures d'arriv√©e au travail\n",
    "- `out_time.csv` : Heures de d√©part du travail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Chargement des fichiers CSV principaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des donn√©es principales\n",
    "general_data = pd.read_csv('data/general_data.csv')\n",
    "employee_survey = pd.read_csv('data/employee_survey_data.csv')\n",
    "manager_survey = pd.read_csv('data/manager_survey_data.csv')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"GENERAL DATA\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Shape: {general_data.shape}\")\n",
    "print(f\"\\nColonnes: {list(general_data.columns)}\")\n",
    "display(general_data.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EMPLOYEE SURVEY DATA\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Shape: {employee_survey.shape}\")\n",
    "display(employee_survey.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MANAGER SURVEY DATA\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Shape: {manager_survey.shape}\")\n",
    "display(manager_survey.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Chargement et traitement des donn√©es de pointage (in_time / out_time)\n",
    "\n",
    "Les fichiers `in_time.csv` et `out_time.csv` contiennent les heures d'arriv√©e et de d√©part des employ√©s pour chaque jour de l'ann√©e 2015. Nous allons cr√©er des features agr√©g√©es :\n",
    "\n",
    "- **Arrive_mean** : Moyenne des heures d'arriv√©e\n",
    "- **Departure_mean** : Moyenne des heures de d√©part  \n",
    "- **Worktime_mean** : Moyenne des heures travaill√©es par jour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des donn√©es de pointage\n",
    "in_time = pd.read_csv('data/in_time.csv')\n",
    "out_time = pd.read_csv('data/out_time.csv')\n",
    "\n",
    "print(f\"in_time shape: {in_time.shape}\")\n",
    "print(f\"out_time shape: {out_time.shape}\")\n",
    "print(f\"\\nNombre de jours enregistr√©s: {len(in_time.columns) - 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_features(in_time_df, out_time_df):\n",
    "    \"\"\"\n",
    "    Extrait les features temporelles des donn√©es de pointage.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame avec EmployeeID, Arrive_mean, Departure_mean, Worktime_mean\n",
    "    \"\"\"\n",
    "    # Colonnes de dates (toutes sauf EmployeeID)\n",
    "    date_cols = [col for col in in_time_df.columns if col != 'EmployeeID']\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for _, row_in in in_time_df.iterrows():\n",
    "        emp_id = row_in['EmployeeID']\n",
    "        row_out = out_time_df[out_time_df['EmployeeID'] == emp_id].iloc[0]\n",
    "        \n",
    "        arrive_times = []  # En heures d√©cimales\n",
    "        depart_times = []  # En heures d√©cimales\n",
    "        work_durations = []  # En heures\n",
    "        \n",
    "        for date_col in date_cols:\n",
    "            in_val = row_in[date_col]\n",
    "            out_val = row_out[date_col]\n",
    "            \n",
    "            # Skip si NA (jour non travaill√©)\n",
    "            if pd.isna(in_val) or pd.isna(out_val) or in_val == 'NA' or out_val == 'NA':\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Parse datetime\n",
    "                in_dt = pd.to_datetime(in_val, format='%d/%m/%Y %H:%M')\n",
    "                out_dt = pd.to_datetime(out_val, format='%d/%m/%Y %H:%M')\n",
    "                \n",
    "                # Heure d'arriv√©e en d√©cimal (ex: 9h30 = 9.5)\n",
    "                arrive_decimal = in_dt.hour + in_dt.minute / 60\n",
    "                depart_decimal = out_dt.hour + out_dt.minute / 60\n",
    "                \n",
    "                # Dur√©e de travail en heures\n",
    "                work_hours = (out_dt - in_dt).total_seconds() / 3600\n",
    "                \n",
    "                # Validation: dur√©e raisonnable (entre 1h et 16h)\n",
    "                if 1 <= work_hours <= 16:\n",
    "                    arrive_times.append(arrive_decimal)\n",
    "                    depart_times.append(depart_decimal)\n",
    "                    work_durations.append(work_hours)\n",
    "                    \n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        # Calcul des moyennes\n",
    "        results.append({\n",
    "            'EmployeeID': emp_id,\n",
    "            'Arrive_mean': np.mean(arrive_times) if arrive_times else np.nan,\n",
    "            'Departure_mean': np.mean(depart_times) if depart_times else np.nan,\n",
    "            'Worktime_mean': np.mean(work_durations) if work_durations else np.nan\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Extraction des features temporelles\n",
    "time_features = extract_time_features(in_time, out_time)\n",
    "\n",
    "print(\"Features temporelles extraites:\")\n",
    "display(time_features.head(10))\n",
    "print(f\"\\nStatistiques:\")\n",
    "display(time_features.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Jointure des DataFrames\n",
    "\n",
    "Fusion de toutes les sources de donn√©es en un seul DataFrame via `EmployeeID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jointure de tous les DataFrames\n",
    "df = general_data.copy()\n",
    "\n",
    "# Merge avec employee survey\n",
    "df = df.merge(employee_survey, on='EmployeeID', how='left')\n",
    "\n",
    "# Merge avec manager survey\n",
    "df = df.merge(manager_survey, on='EmployeeID', how='left')\n",
    "\n",
    "# Merge avec time features\n",
    "df = df.merge(time_features, on='EmployeeID', how='left')\n",
    "\n",
    "print(f\"DataFrame final shape: {df.shape}\")\n",
    "print(f\"\\nColonnes ({len(df.columns)}):\")\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(f\"  {i+1}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu du DataFrame fusionn√©\n",
    "print(\"Aper√ßu des donn√©es:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nTypes de donn√©es:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2Ô∏è Analyse Exploratoire des Donn√©es (EDA)\n",
    "\n",
    "Avant de construire notre mod√®le, analysons les donn√©es pour comprendre les patterns et relations entre variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Distribution de la variable cible (Attrition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution de la variable cible\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Countplot\n",
    "attrition_counts = df['Attrition'].value_counts()\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "axes[0].bar(attrition_counts.index, attrition_counts.values, color=colors, edgecolor='black')\n",
    "axes[0].set_title('Distribution de l\\'Attrition', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Attrition')\n",
    "axes[0].set_ylabel('Nombre d\\'employ√©s')\n",
    "\n",
    "# Ajout des valeurs sur les barres\n",
    "for i, (idx, val) in enumerate(zip(attrition_counts.index, attrition_counts.values)):\n",
    "    axes[0].text(idx, val + 20, str(val), ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(attrition_counts.values, labels=attrition_counts.index, autopct='%1.1f%%',\n",
    "            colors=colors, explode=(0, 0.05), shadow=True, startangle=90)\n",
    "axes[1].set_title('Proportion de l\\'Attrition', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Stats\n",
    "attrition_rate = (df['Attrition'] == 'Yes').mean() * 100\n",
    "print(f\"\\nüìä Taux d'attrition: {attrition_rate:.2f}%\")\n",
    "print(f\"‚ö†Ô∏è  Dataset d√©s√©quilibr√© - √† prendre en compte pour le mod√®le\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Heatmap de corr√©lation bivari√©e\n",
    "\n",
    "Visualisons les corr√©lations entre les variables num√©riques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage temporaire de Attrition pour la corr√©lation\n",
    "df_corr = df.copy()\n",
    "df_corr['Attrition_encoded'] = (df_corr['Attrition'] == 'Yes').astype(int)\n",
    "\n",
    "# S√©lection des colonnes num√©riques\n",
    "numeric_cols = df_corr.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Matrice de corr√©lation\n",
    "correlation_matrix = df_corr[numeric_cols].corr()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(16, 12))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f', \n",
    "            cmap='RdBu_r', center=0, square=True, linewidths=0.5,\n",
    "            annot_kws={'size': 8}, vmin=-1, vmax=1)\n",
    "plt.title('Heatmap de Corr√©lation Bivari√©e', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top corr√©lations avec Attrition\n",
    "print(\"\\nüìà Top 10 corr√©lations avec Attrition:\")\n",
    "attrition_corr = correlation_matrix['Attrition_encoded'].drop('Attrition_encoded').abs().sort_values(ascending=False)\n",
    "for col, corr in attrition_corr.head(10).items():\n",
    "    direction = '+' if correlation_matrix.loc[col, 'Attrition_encoded'] > 0 else '-'\n",
    "    print(f\"  {direction} {col}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Distribution des variables num√©riques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables num√©riques √† visualiser (exclure IDs)\n",
    "numeric_features = [col for col in numeric_cols if 'ID' not in col and 'encoded' not in col]\n",
    "\n",
    "# Calcul du nombre de lignes n√©cessaires\n",
    "n_cols = 4\n",
    "n_rows = (len(numeric_features) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 3.5 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(numeric_features):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Histogramme par Attrition\n",
    "    for attrition_val, color, label in [('No', '#2ecc71', 'Reste'), ('Yes', '#e74c3c', 'Part')]:\n",
    "        data = df[df['Attrition'] == attrition_val][col].dropna()\n",
    "        ax.hist(data, bins=20, alpha=0.6, color=color, label=label, edgecolor='white')\n",
    "    \n",
    "    ax.set_title(col, fontsize=10, fontweight='bold')\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.tick_params(labelsize=8)\n",
    "\n",
    "# Masquer les axes vides\n",
    "for idx in range(len(numeric_features), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.suptitle('Distribution des Variables Num√©riques par Attrition', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Distribution des variables cat√©gorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables cat√©gorielles\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_cols = [col for col in categorical_cols if col != 'Attrition']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(categorical_cols[:6]):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Calcul des proportions d'attrition par cat√©gorie\n",
    "    cross_tab = pd.crosstab(df[col], df['Attrition'], normalize='index') * 100\n",
    "    \n",
    "    cross_tab.plot(kind='bar', ax=ax, color=['#2ecc71', '#e74c3c'], edgecolor='black')\n",
    "    ax.set_title(f'Attrition par {col}', fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Pourcentage (%)')\n",
    "    ax.legend(['Reste', 'Part'], loc='upper right')\n",
    "    ax.tick_params(axis='x', rotation=45, labelsize=9)\n",
    "    ax.set_ylim(0, 100)\n",
    "\n",
    "plt.suptitle('Taux d\\'Attrition par Variable Cat√©gorielle', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3Ô∏è Nettoyage des Donn√©es\n",
    "\n",
    "√âtapes de nettoyage :\n",
    "1. Retrait des colonnes probl√©matiques (colin√©arit√©, RGPD, √©thique, leakage)\n",
    "2. Imputation des valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Analyse des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des valeurs manquantes\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({'Missing': missing, 'Percentage': missing_pct})\n",
    "missing_df = missing_df[missing_df['Missing'] > 0].sort_values('Missing', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(\"üìä Colonnes avec valeurs manquantes:\")\n",
    "    display(missing_df)\n",
    "    \n",
    "    # Visualisation\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.bar(missing_df.index, missing_df['Percentage'], color='#e74c3c', edgecolor='black')\n",
    "    plt.title('Pourcentage de Valeurs Manquantes par Colonne', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Pourcentage (%)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚úÖ Aucune valeur manquante dans le dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Identification et retrait des colonnes probl√©matiques\n",
    "\n",
    "**Crit√®res de suppression :**\n",
    "- **Colin√©arit√©** : Variables fortement corr√©l√©es entre elles (redondance)\n",
    "- **Non-conformit√© RGPD** : Donn√©es personnelles sensibles\n",
    "- **√âthique** : Variables potentiellement discriminatoires\n",
    "- **Leakage** : Variables qui fuiteraient l'information cible\n",
    "- **Non pertinence** : Variables sans pouvoir pr√©dictif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes √† supprimer avec justification\n",
    "columns_to_drop = {\n",
    "    'EmployeeID': 'Non pertinent - Identifiant unique sans valeur pr√©dictive',\n",
    "    'Gender': '√âthique - Potentiellement discriminatoire (biais de genre)',\n",
    "    'Over18': 'Non pertinent - Valeur constante (tous > 18 ans)',\n",
    "    'StandardHours': 'Non pertinent - Valeur constante (80h pour tous)',\n",
    "    'EmployeeCount': 'Non pertinent - Valeur constante (1 pour tous)',\n",
    "    'Departure_mean': 'Trop corr√©l√© avec worktime mean',\n",
    "    'Age': \"Ethique - discrimination sur l'age\",\n",
    "    'MaritalStatus': '√âthique - Information personnelle potentiellement discriminatoire'\n",
    "}\n",
    "\n",
    "# V√©rifier les colonnes qui existent r√©ellement\n",
    "existing_cols_to_drop = [col for col in columns_to_drop.keys() if col in df.columns]\n",
    "\n",
    "print(\"üóëÔ∏è Colonnes √† supprimer:\")\n",
    "print(\"=\" * 70)\n",
    "for col in existing_cols_to_drop:\n",
    "    reason = columns_to_drop[col]\n",
    "    print(f\"  ‚Ä¢ {col}: {reason}\")\n",
    "\n",
    "# Suppression des colonnes\n",
    "df_clean = df.drop(columns=existing_cols_to_drop, errors='ignore')\n",
    "\n",
    "print(f\"\\n‚úÖ Colonnes supprim√©es: {len(existing_cols_to_drop)}\")\n",
    "print(f\"üìä Shape apr√®s suppression: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 D√©tection et traitement de la colin√©arit√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse de colin√©arit√© entre variables num√©riques\n",
    "numeric_cols_clean = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "corr_matrix = df_clean[numeric_cols_clean].corr().abs()\n",
    "\n",
    "# Trouver les paires fortement corr√©l√©es (> 0.85)\n",
    "threshold = 0.85\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "high_corr_pairs = []\n",
    "for col in upper_tri.columns:\n",
    "    for idx in upper_tri.index:\n",
    "        if upper_tri.loc[idx, col] > threshold:\n",
    "            high_corr_pairs.append((idx, col, upper_tri.loc[idx, col]))\n",
    "\n",
    "if high_corr_pairs:\n",
    "    print(f\"‚ö†Ô∏è Paires avec corr√©lation > {threshold}:\")\n",
    "    for var1, var2, corr in high_corr_pairs:\n",
    "        print(f\"  ‚Ä¢ {var1} ‚Üî {var2}: {corr:.3f}\")\n",
    "    \n",
    "    # Colonnes √† supprimer (garder celle avec plus de corr√©lation avec Attrition)\n",
    "    cols_to_remove = set()\n",
    "    df_temp = df_clean.copy()\n",
    "    df_temp['Attrition_num'] = (df_temp['Attrition'] == 'Yes').astype(int)\n",
    "    \n",
    "    for var1, var2, _ in high_corr_pairs:\n",
    "        corr1 = abs(df_temp[var1].corr(df_temp['Attrition_num']))\n",
    "        corr2 = abs(df_temp[var2].corr(df_temp['Attrition_num']))\n",
    "        \n",
    "        # Supprimer celle avec moins de corr√©lation avec la cible\n",
    "        to_remove = var1 if corr1 < corr2 else var2\n",
    "        cols_to_remove.add(to_remove)\n",
    "        print(f\"  ‚Üí Suppression de '{to_remove}' (moins corr√©l√© avec Attrition)\")\n",
    "    \n",
    "    df_clean = df_clean.drop(columns=list(cols_to_remove), errors='ignore')\n",
    "    print(f\"\\n‚úÖ Shape apr√®s suppression colin√©arit√©: {df_clean.shape}\")\n",
    "else:\n",
    "    print(\"‚úÖ Aucune colin√©arit√© forte d√©tect√©e.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Imputation des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rification des valeurs manquantes apr√®s nettoyage\n",
    "missing_after = df_clean.isnull().sum()\n",
    "missing_cols = missing_after[missing_after > 0]\n",
    "\n",
    "if len(missing_cols) > 0:\n",
    "    print(\"üìä Colonnes avec valeurs manquantes √† imputer:\")\n",
    "    for col, count in missing_cols.items():\n",
    "        dtype = df_clean[col].dtype\n",
    "        print(f\"  ‚Ä¢ {col}: {count} valeurs ({dtype})\")\n",
    "    \n",
    "    # Imputation\n",
    "    for col in missing_cols.index:\n",
    "        if df_clean[col].dtype in ['float64', 'int64']:\n",
    "            # Imputation par la m√©diane pour les num√©riques\n",
    "            median_val = df_clean[col].median()\n",
    "            df_clean[col] = df_clean[col].fillna(median_val)\n",
    "            print(f\"  ‚Üí {col}: imput√© par m√©diane ({median_val:.2f})\")\n",
    "        else:\n",
    "            # Imputation par le mode pour les cat√©gorielles\n",
    "            mode_val = df_clean[col].mode()[0]\n",
    "            df_clean[col] = df_clean[col].fillna(mode_val)\n",
    "            print(f\"  ‚Üí {col}: imput√© par mode ({mode_val})\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Imputation termin√©e!\")\n",
    "else:\n",
    "    print(\"‚úÖ Aucune valeur manquante √† imputer!\")\n",
    "\n",
    "# V√©rification finale\n",
    "print(f\"\\nüìä Valeurs manquantes restantes: {df_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Affichage du DataFrame final nettoy√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"DATAFRAME FINAL NETTOY√â\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nShape: {df_clean.shape}\")\n",
    "print(f\"\\nColonnes ({len(df_clean.columns)}):\")\n",
    "\n",
    "# S√©parer num√©riques et cat√©gorielles\n",
    "num_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = df_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\n  üìä Num√©riques ({len(num_cols)}): {num_cols}\")\n",
    "print(f\"\\n  üìù Cat√©gorielles ({len(cat_cols)}): {cat_cols}\")\n",
    "\n",
    "display(df_clean.head(10))\n",
    "\n",
    "print(\"\\nüìà Statistiques descriptives:\")\n",
    "display(df_clean.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4Ô∏è Pipeline Machine Learning\n",
    "\n",
    "Construction du pipeline complet :\n",
    "1. Pr√©paration des features et target\n",
    "2. Split train/test/validation\n",
    "3. Preprocessing (encoding + standardisation)\n",
    "4. D√©finition des mod√®les et hyperparam√®tres\n",
    "5. Tuning et entra√Ænement\n",
    "6. Comparaison et s√©lection du meilleur mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Pr√©paration des features et target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©paration features / target\n",
    "X = df_clean.drop(columns=['Attrition'])\n",
    "y = (df_clean['Attrition'] == 'Yes').astype(int)  # 1 = Part, 0 = Reste\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nDistribution target:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Split Train / Test / Validation\n",
    "\n",
    "- **Train** : 70% - Pour l'entra√Ænement des mod√®les\n",
    "- **Test** : 15% - Pour l'√©valuation finale\n",
    "- **Validation** : 15% - Pour l'analyse approfondie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle et split\n",
    "# Premier split: 70% train, 30% temp\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=RANDOM_STATE, stratify=y, shuffle=True\n",
    ")\n",
    "\n",
    "# Second split: 50/50 pour test et validation (15% chacun du total)\n",
    "X_test, X_val, y_test, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=RANDOM_STATE, stratify=y_temp, shuffle=True\n",
    ")\n",
    "\n",
    "print(\"üìä R√©partition des donn√©es:\")\n",
    "print(f\"  ‚Ä¢ Train:      {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"  ‚Ä¢ Test:       {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"  ‚Ä¢ Validation: {X_val.shape[0]} samples ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nüìà Distribution de la cible par set:\")\n",
    "for name, y_set in [('Train', y_train), ('Test', y_test), ('Validation', y_val)]:\n",
    "    pct_pos = y_set.mean() * 100\n",
    "    print(f\"  ‚Ä¢ {name}: {pct_pos:.1f}% d'attrition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Pipeline de Preprocessing (Encoding + Standardisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identification des types de colonnes\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Features num√©riques ({len(numeric_features)}): {numeric_features}\")\n",
    "print(f\"\\nFeatures cat√©gorielles ({len(categorical_features)}): {categorical_features}\")\n",
    "\n",
    "# Pipeline de preprocessing\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit et transform sur train\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "\n",
    "# R√©cup√©ration des noms de features apr√®s encoding\n",
    "cat_feature_names = preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_features).tolist()\n",
    "all_feature_names = numeric_features + cat_feature_names\n",
    "\n",
    "print(f\"\\n‚úÖ Preprocessing termin√©!\")\n",
    "print(f\"   Shape apr√®s transformation: {X_train_processed.shape}\")\n",
    "print(f\"   Nombre total de features: {len(all_feature_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 D√©finition des Mod√®les et Hyperparam√®tres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finition des mod√®les et leurs grilles d'hyperparam√®tres\n",
    "models_config = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),\n",
    "        'params': {\n",
    "            'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear', 'saga'],\n",
    "            'class_weight': [None, 'balanced']\n",
    "        }\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [5, 10, 15, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'class_weight': [None, 'balanced']\n",
    "        }\n",
    "    },\n",
    "    'Perceptron': {\n",
    "        'model': Perceptron(random_state=RANDOM_STATE),\n",
    "        'params': {\n",
    "            'penalty': [None, 'l2', 'l1', 'elasticnet'],\n",
    "            'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "            'max_iter': [500, 1000, 2000],\n",
    "            'class_weight': [None, 'balanced']\n",
    "        }\n",
    "    },\n",
    "    'HistGradientBoosting': {\n",
    "        'model': HistGradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "        'params': {\n",
    "            'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "            'max_iter': [100, 200, 300],\n",
    "            'max_depth': [3, 5, 7, None],\n",
    "            'min_samples_leaf': [10, 20, 30],\n",
    "            'l2_regularization': [0, 0.1, 1.0]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üìã Mod√®les configur√©s:\")\n",
    "for name, config in models_config.items():\n",
    "    n_combinations = 1\n",
    "    for param_values in config['params'].values():\n",
    "        n_combinations *= len(param_values)\n",
    "    print(f\"  ‚Ä¢ {name}: {n_combinations} combinaisons d'hyperparam√®tres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Tuning des Hyperparam√®tres et Entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stockage des r√©sultats\n",
    "results = {}\n",
    "best_models = {}\n",
    "\n",
    "print(\"üöÄ Lancement du tuning des hyperparam√®tres...\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for model_name, config in models_config.items():\n",
    "    print(f\"\\nüìä {model_name}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # GridSearchCV avec cross-validation\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=config['model'],\n",
    "        param_grid=config['params'],\n",
    "        cv=5,\n",
    "        scoring='f1',  # F1 car dataset d√©s√©quilibr√©\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Fit\n",
    "    grid_search.fit(X_train_processed, y_train)\n",
    "    \n",
    "    # Meilleur mod√®le\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_models[model_name] = best_model\n",
    "    \n",
    "    # Pr√©dictions sur test\n",
    "    y_pred = best_model.predict(X_test_processed)\n",
    "    y_proba = best_model.predict_proba(X_test_processed)[:, 1] if hasattr(best_model, 'predict_proba') else None\n",
    "    \n",
    "    # M√©triques\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_proba) if y_proba is not None else None,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'cv_score': grid_search.best_score_\n",
    "    }\n",
    "    results[model_name] = metrics\n",
    "    \n",
    "    # Affichage\n",
    "    print(f\"  Best CV F1 Score: {metrics['cv_score']:.4f}\")\n",
    "    print(f\"  Test Accuracy:    {metrics['accuracy']:.4f}\")\n",
    "    print(f\"  Test Precision:   {metrics['precision']:.4f}\")\n",
    "    print(f\"  Test Recall:      {metrics['recall']:.4f}\")\n",
    "    print(f\"  Test F1:          {metrics['f1']:.4f}\")\n",
    "    if metrics['roc_auc']:\n",
    "        print(f\"  Test ROC AUC:     {metrics['roc_auc']:.4f}\")\n",
    "    print(f\"  Best params: {metrics['best_params']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ Tuning termin√©!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Graphiques Comparatifs des Mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame des r√©sultats\n",
    "from pandas.io.formats.style import Styler\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': results.keys(),\n",
    "    'Accuracy': [r['accuracy'] for r in results.values()],\n",
    "    'Precision': [r['precision'] for r in results.values()],\n",
    "    'Recall': [r['recall'] for r in results.values()],\n",
    "    'F1 Score': [r['f1'] for r in results.values()],\n",
    "    'ROC AUC': [r['roc_auc'] if r['roc_auc'] else 0 for r in results.values()],\n",
    "    'CV F1': [r['cv_score'] for r in results.values()]\n",
    "}).set_index('Model')\n",
    "\n",
    "print(\"üìä Tableau comparatif des performances:\")\n",
    "display(results_df.style.highlight_max(axis=0, color='green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation comparative\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 1. Barplot des m√©triques\n",
    "metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "x = np.arange(len(results_df.index))\n",
    "width = 0.2\n",
    "colors = ['#3498db', '#2ecc71', '#e74c3c', '#9b59b6']\n",
    "\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    axes[0].bar(x + i * width, results_df[metric], width, label=metric, color=colors[i])\n",
    "\n",
    "axes[0].set_xlabel('Mod√®le')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_title('Comparaison des M√©triques par Mod√®le', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x + width * 1.5)\n",
    "axes[0].set_xticklabels(results_df.index, rotation=15, ha='right')\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[0].axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# 2. ROC Curves\n",
    "for model_name, model in best_models.items():\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_proba = model.predict_proba(X_test_processed)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        axes[1].plot(fpr, tpr, label=f'{model_name} (AUC={auc:.3f})', linewidth=2)\n",
    "\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', label='Random (AUC=0.5)')\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('Courbes ROC', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(loc='lower right')\n",
    "axes[1].set_xlim([0, 1])\n",
    "axes[1].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Choix du Meilleur Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©lection du meilleur mod√®le bas√© sur F1 Score (√©quilibre precision/recall)\n",
    "best_model_name = results_df['F1 Score'].idxmax()\n",
    "best_model_final = best_models[best_model_name]\n",
    "best_metrics = results[best_model_name]\n",
    "\n",
    "print(\"üèÜ MEILLEUR MOD√àLE S√âLECTIONN√â\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\n  Mod√®le: {best_model_name}\")\n",
    "print(f\"\\n  Performances sur le set de test:\")\n",
    "print(f\"    ‚Ä¢ Accuracy:  {best_metrics['accuracy']:.4f}\")\n",
    "print(f\"    ‚Ä¢ Precision: {best_metrics['precision']:.4f}\")\n",
    "print(f\"    ‚Ä¢ Recall:    {best_metrics['recall']:.4f}\")\n",
    "print(f\"    ‚Ä¢ F1 Score:  {best_metrics['f1']:.4f}\")\n",
    "if best_metrics['roc_auc']:\n",
    "    print(f\"    ‚Ä¢ ROC AUC:   {best_metrics['roc_auc']:.4f}\")\n",
    "print(f\"\\n  Hyperparam√®tres optimaux:\")\n",
    "for param, value in best_metrics['best_params'].items():\n",
    "    print(f\"    ‚Ä¢ {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 Sauvegarde du Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du mod√®le et du preprocessor\n",
    "model_filename = 'attrition_model.joblib'\n",
    "preprocessor_filename = 'attrition_preprocessor.joblib'\n",
    "\n",
    "joblib.dump(best_model_final, model_filename)\n",
    "joblib.dump(preprocessor, preprocessor_filename)\n",
    "\n",
    "print(\"üíæ Mod√®le sauvegard√©!\")\n",
    "print(f\"  ‚Ä¢ Mod√®le:       {model_filename}\")\n",
    "print(f\"  ‚Ä¢ Preprocessor: {preprocessor_filename}\")\n",
    "\n",
    "# Sauvegarde des m√©tadonn√©es\n",
    "metadata = {\n",
    "    'model_name': best_model_name,\n",
    "    'best_params': best_metrics['best_params'],\n",
    "    'metrics': {\n",
    "        'accuracy': best_metrics['accuracy'],\n",
    "        'precision': best_metrics['precision'],\n",
    "        'recall': best_metrics['recall'],\n",
    "        'f1': best_metrics['f1'],\n",
    "        'roc_auc': best_metrics['roc_auc']\n",
    "    },\n",
    "    'feature_names': all_feature_names,\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "joblib.dump(metadata, 'attrition_metadata.joblib')\n",
    "print(f\"  ‚Ä¢ Metadata:     attrition_metadata.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5Ô∏è Analyse Approfondie du Mod√®le\n",
    "\n",
    "Analyse d√©taill√©e sur le set de validation pour comprendre les pr√©dictions et les facteurs d'attrition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Performance sur le Set de Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©dictions sur validation\n",
    "y_val_pred = best_model_final.predict(X_val_processed)\n",
    "y_val_proba = best_model_final.predict_proba(X_val_processed)[:, 1] if hasattr(best_model_final, 'predict_proba') else None\n",
    "\n",
    "print(\"üìä Performance sur le set de VALIDATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\n{classification_report(y_val, y_val_pred, target_names=['Reste', 'Part'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations avanc√©es sur validation\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# 1. Matrice de confusion\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 0],\n",
    "            xticklabels=['Reste', 'Part'], yticklabels=['Reste', 'Part'])\n",
    "axes[0, 0].set_title('Matrice de Confusion (Validation)', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Pr√©dit')\n",
    "axes[0, 0].set_ylabel('R√©el')\n",
    "\n",
    "# 2. Courbe ROC\n",
    "if y_val_proba is not None:\n",
    "    fpr, tpr, thresholds = roc_curve(y_val, y_val_proba)\n",
    "    auc = roc_auc_score(y_val, y_val_proba)\n",
    "    axes[0, 1].plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC (AUC = {auc:.3f})')\n",
    "    axes[0, 1].fill_between(fpr, tpr, alpha=0.3)\n",
    "    axes[0, 1].plot([0, 1], [0, 1], 'k--')\n",
    "    axes[0, 1].set_xlabel('False Positive Rate')\n",
    "    axes[0, 1].set_ylabel('True Positive Rate')\n",
    "    axes[0, 1].set_title('Courbe ROC (Validation)', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].legend(loc='lower right')\n",
    "\n",
    "# 3. Courbe Precision-Recall\n",
    "if y_val_proba is not None:\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(y_val, y_val_proba)\n",
    "    ap = average_precision_score(y_val, y_val_proba)\n",
    "    axes[1, 0].plot(recall_curve, precision_curve, 'g-', linewidth=2, label=f'AP = {ap:.3f}')\n",
    "    axes[1, 0].fill_between(recall_curve, precision_curve, alpha=0.3, color='green')\n",
    "    axes[1, 0].set_xlabel('Recall')\n",
    "    axes[1, 0].set_ylabel('Precision')\n",
    "    axes[1, 0].set_title('Courbe Precision-Recall (Validation)', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].legend(loc='upper right')\n",
    "\n",
    "# 4. Distribution des probabilit√©s\n",
    "if y_val_proba is not None:\n",
    "    for label, color, name in [(0, '#2ecc71', 'Reste'), (1, '#e74c3c', 'Part')]:\n",
    "        mask = y_val == label\n",
    "        axes[1, 1].hist(y_val_proba[mask], bins=30, alpha=0.6, color=color, label=name, edgecolor='white')\n",
    "    axes[1, 1].axvline(x=0.5, color='black', linestyle='--', label='Seuil (0.5)')\n",
    "    axes[1, 1].set_xlabel('Probabilit√© de D√©part')\n",
    "    axes[1, 1].set_ylabel('Fr√©quence')\n",
    "    axes[1, 1].set_title('Distribution des Probabilit√©s Pr√©dites', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Importance des Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "print(\"üîÑ Calcul de l'importance des features (permutation)...\")\n",
    "\n",
    "\n",
    "perm_importance = permutation_importance(\n",
    "    best_model_final,  \n",
    "    X_test_processed, \n",
    "    y_test,\n",
    "    n_repeats=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "importances = perm_importance.importances_mean\n",
    "\n",
    "# DataFrame des importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Importance': importances,\n",
    "    'Std': perm_importance.importances_std\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"üìä Top 15 Features les plus importantes:\")\n",
    "display(feature_importance_df.head(15))\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "top_n = 20\n",
    "top_features = feature_importance_df.head(top_n)\n",
    "\n",
    "# Barplot horizontal avec barres d'erreur\n",
    "colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(top_features)))\n",
    "axes[0].barh(\n",
    "    range(len(top_features)), \n",
    "    top_features['Importance'].values, \n",
    "    xerr=top_features['Std'].values,\n",
    "    color=colors,\n",
    "    alpha=0.8\n",
    ")\n",
    "axes[0].set_yticks(range(len(top_features)))\n",
    "axes[0].set_yticklabels(top_features['Feature'].values)\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel('Importance (Permutation)')\n",
    "axes[0].set_title(f'Top {top_n} Features les Plus Importantes', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Importance cumul√©e\n",
    "cumulative_importance = np.cumsum(feature_importance_df['Importance'].values / feature_importance_df['Importance'].sum())\n",
    "axes[1].plot(range(1, len(cumulative_importance) + 1), cumulative_importance, 'b-', linewidth=2)\n",
    "axes[1].axhline(y=0.9, color='r', linestyle='--', label='90% importance')\n",
    "axes[1].axhline(y=0.95, color='orange', linestyle='--', label='95% importance')\n",
    "\n",
    "n_90 = np.argmax(cumulative_importance >= 0.9) + 1\n",
    "n_95 = np.argmax(cumulative_importance >= 0.95) + 1\n",
    "axes[1].axvline(x=n_90, color='r', linestyle=':', alpha=0.5)\n",
    "axes[1].axvline(x=n_95, color='orange', linestyle=':', alpha=0.5)\n",
    "\n",
    "axes[1].set_xlabel('Nombre de Features')\n",
    "axes[1].set_ylabel('Importance Cumul√©e')\n",
    "axes[1].set_title('Importance Cumul√©e des Features', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].set_xlim([0, len(cumulative_importance)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìà {n_90} features expliquent 90% de l'importance\")\n",
    "print(f\"üìà {n_95} features expliquent 95% de l'importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Analyse des Features Importantes par D√©partement\n",
    "\n",
    "√âtudions comment les facteurs d'attrition varient selon le d√©partement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse par d√©partement\n",
    "if 'Department' in df_clean.columns:\n",
    "    departments = df_clean['Department'].unique()\n",
    "    \n",
    "    print(\"üìä Taux d'attrition par d√©partement:\")\n",
    "    dept_attrition = df_clean.groupby('Department')['Attrition'].apply(\n",
    "        lambda x: (x == 'Yes').mean() * 100\n",
    "    ).sort_values(ascending=False)\n",
    "    \n",
    "    for dept, rate in dept_attrition.items():\n",
    "        print(f\"  ‚Ä¢ {dept}: {rate:.1f}%\")\n",
    "    \n",
    "    # Visualisation\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Barplot taux d'attrition\n",
    "    colors = plt.cm.RdYlGn_r(dept_attrition.values / dept_attrition.max())\n",
    "    axes[0].bar(dept_attrition.index, dept_attrition.values, color=colors, edgecolor='black')\n",
    "    axes[0].set_ylabel('Taux d\\'attrition (%)')\n",
    "    axes[0].set_title('Taux d\\'Attrition par D√©partement', fontsize=14, fontweight='bold')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Ajout des valeurs\n",
    "    for i, (idx, val) in enumerate(dept_attrition.items()):\n",
    "        axes[0].text(i, val + 0.5, f'{val:.1f}%', ha='center', fontsize=10)\n",
    "    \n",
    "    # Nombre d'employ√©s par d√©partement\n",
    "    dept_counts = df_clean['Department'].value_counts()\n",
    "    axes[1].pie(dept_counts.values, labels=dept_counts.index, autopct='%1.1f%%',\n",
    "                colors=plt.cm.Set3.colors[:len(dept_counts)], explode=[0.02]*len(dept_counts))\n",
    "    axes[1].set_title('R√©partition des Employ√©s par D√©partement', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des features num√©riques importantes par d√©partement et attrition\n",
    "if importances is not None and 'Department' in df_clean.columns:\n",
    "    # Top 4 features num√©riques importantes\n",
    "    top_numeric_features = [\n",
    "        f for f in feature_importance_df['Feature'].head(10).values \n",
    "        if f in numeric_features\n",
    "    ][:4]\n",
    "    \n",
    "    if len(top_numeric_features) > 0:\n",
    "        fig, axes = plt.subplots(len(top_numeric_features), 1, figsize=(14, 4 * len(top_numeric_features)))\n",
    "        if len(top_numeric_features) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for idx, feature in enumerate(top_numeric_features):\n",
    "            ax = axes[idx]\n",
    "            \n",
    "            # Boxplot par d√©partement et attrition\n",
    "            data_plot = df_clean[[feature, 'Department', 'Attrition']].copy()\n",
    "            \n",
    "            sns.boxplot(data=data_plot, x='Department', y=feature, hue='Attrition',\n",
    "                       palette=['#2ecc71', '#e74c3c'], ax=ax)\n",
    "            ax.set_title(f'{feature} par D√©partement et Attrition', fontsize=12, fontweight='bold')\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "            ax.legend(title='Attrition', labels=['Reste', 'Part'])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 R√©sum√© et Recommandations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"üìã R√âSUM√â ET RECOMMANDATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüèÜ Meilleur mod√®le: {best_model_name}\")\n",
    "print(f\"   F1 Score: {best_metrics['f1']:.4f}\")\n",
    "if best_metrics['roc_auc']:\n",
    "    print(f\"   ROC AUC: {best_metrics['roc_auc']:.4f}\")\n",
    "\n",
    "if importances is not None:\n",
    "    print(\"\\nüìä Top 5 facteurs d'attrition:\")\n",
    "    for i, row in feature_importance_df.head(5).iterrows():\n",
    "        print(f\"   {i+1}. {row['Feature']} (importance: {row['Importance']:.4f})\")\n",
    "\n",
    "print(\"\\nüí° Recommandations pour r√©duire l'attrition:\")\n",
    "print(\"   ‚Ä¢ Surveiller les employ√©s avec des scores bas sur les features importantes\")\n",
    "print(\"   ‚Ä¢ Mettre en place des programmes de r√©tention cibl√©s par d√©partement\")\n",
    "print(\"   ‚Ä¢ Utiliser ce mod√®le pour identifier proactivement les employ√©s √† risque\")\n",
    "print(\"   ‚Ä¢ Collecter des donn√©es suppl√©mentaires sur les raisons de d√©part\")\n",
    "\n",
    "print(\"\\nüìÅ Fichiers sauvegard√©s:\")\n",
    "print(\"   ‚Ä¢ attrition_model.joblib\")\n",
    "print(\"   ‚Ä¢ attrition_preprocessor.joblib\")\n",
    "print(\"   ‚Ä¢ attrition_metadata.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
